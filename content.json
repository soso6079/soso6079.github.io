{"posts":[{"title":"4주차 회고록(NH 공모전 및 도메인 기초)","text":"아쉽게 끝난 공모전본격적으로 NH 공모전과 병행하며 보낸 한 주였다. 월요일이 휴일이라 오프라인으로 모여 하루종일 코딩하며 하루를 보냈고 그 후로도 저녁 9시부터 새벽까진 따로 공모전을 진행했다. 다만 가설 검증을 먼저 빠르게 해보고 진행해야 한다는 점을 잊고, 틀린 가설로 계속해서 분류를 시도했다는걸 제출 이틀 전에 알았다.난 금요일부터 밤새 달리고 주말도 달려서 제출하고 싶었지만.. 분석 경험이 많은 팀원 분이 멈출 줄 아는 것도 용기라고 말씀하셔서 깨끗하게 포기했다. 당장 공모전에만 매달릴 수 있는 상황도 아니었고 달린다고 좋은 결과가 나온다는 보장도 없었기 때문에 순순히 패배를 인정할 수 밖에 없었다. 대신 다같이 회고록을 적어보자는 말이 나왔고, 화면 공유를 하며 분석 과정과 서로 느낀 점을 공유했다. 이게 또 새로운 경험이었는데 정말 도움이 많이 됐다. 단순히 실패한 공모전으로 끝나버리진 않았다. 빡세다 빡세 부캠문제는 부스트캠프였다. 매주 힘들다고 느끼지만 매주 새롭게 빡세다. 도메인 기초 이론과 데이터 시각화 강의를 동시에 배우는 한주였는데, 데이터 시각화는 거의 못봤다. 한주동안 뮤트해버린 안수빈 마스터님께 진심으로 죄송..🙇 추천 시스템은 3강까지 알고 있던 내용들이라 조금 만만하게 봤다. 아 확실히 기초적인거 배우는구나, 싶었는데 기초적인건 나였고ㅋㅋ 본격적으로 모델 기반 추천 시스템이 나오고 잘 이해가 되지 않는 부분들이 나왔다. 이해가 안된다고 붙잡고 있는 스타일은 아니라 일단 넘기고 과제로 넘어갔다. 제대로 보지도 못한 과제과제는 그 전에 비하면 어렵지 않았는데 계속 연산 과정에서 차원을 못맞춰서 에러가 계속 떴다. 게다가 공모전과 국민취업지원센터 상담 덕분에 시간도 없어서 과제 2는 간단하게 밖에 못봤다. 안그래도 약한 파이토치 구현 부분이었는데, 조금밖에 보지 못한게 아쉬웠다. 이 글을 작성하고 우선 제대로 보지 못한 과제들부터 들여다볼 생각이다. 대학원 컨택이 생각나는 구팀..이제 본격적으로 팀이 꾸려지는 기간인게 느껴진다. 이미 팀을 꾸린 사람들도 꽤 있었다. 솔직히 어느 사람을 만나든 여기 있는 사람들 다 열정도 있고 열심히 할 걸 안다. 시험까지 봐가면서 지원한 곳이니까. 다만 상황이 다르면 마음가짐이 달라진다. 다른 사람들은 모르겠고 일단 나는 그렇다. 난 여전히 절박한 마음을 갖고 있다. 스트레스를 너무 받지 않으려고 과몰입으로는 안넘어가게 노력중이지만.. 만약 꾸려진 팀이 아직 졸업까지 한참 남은 사람이거나 대학원만 희망하는 사람들 밖에 없다면 솔직히 준내 스트레스 받을 것 같다.. 안그래도 하루죙일 집에 갇혀 있으니, 묘한 외로움도 스멀스멀 올라오고 앉았는데. 암튼 이런 상황을 아무것도 안해보고 맞이하긴 싫었다. 할 건 다 해봐야징. 내 구팀 글도 보기 좋게 수정하고 구팀 글을 하나하나 읽어보며 리스트 업했다. 그리고 계속 눈이 가던 사람에게 먼저 DM을 보내놓고 이 글을 쓰고 있다. 끝까지 긍정적인 답장을 못받았던 대학원 컨택 때가 계속 떠오르는 한 주다. 키워드 Apriori 알고리즘 Youtube Recommendation 논문 CDAE (Collaborative Denoising Auto-Encoders for Top-N Recommender systems) 논문 One-Shot Learning","link":"/2022/10/15/4%EC%A3%BC%EC%B0%A8%20%ED%9A%8C%EA%B3%A0%EB%A1%9D(NH%20%EA%B3%B5%EB%AA%A8%EC%A0%84%20%EB%B0%8F%20%EB%8F%84%EB%A9%94%EC%9D%B8%20%EA%B8%B0%EC%B4%88)/"},{"title":"5주차 회고록(구팀)","text":"부캠 시작하고 첫 여유이번 한주는 저번주에 비해 여유로웠다. 공모전도 끝났고 강의 분량도 적었다. 깃허브 특강과 level 2 팀 구성 때문인지 분량을 일부러 많이 안준 것 같았다. 아 추천 시스템만 그랬을 수 있다. 다른 도메인들은 어땠는지 모르겠다.도메인 추천 시스템은 한 강의에서 컨셉에 대한 모델의 발전을 쭉 보여주는 식이다. 그러다보니 영상은 40분 내외인데 배우는 모델은 3~4개씩 된다. 깊이도 꽤 깊게 들어가서 40분 영상이면 1시간 반은 보게 된다. 강의 퀄리티가 굉장히 좋아서 얕지 않은 수준으로 모델들을 알 수 있는데, 확실히 논문을 같이 보면서 정리할 수 있다면 더 좋을 것 같다. 사실 논문을 계속 보고 싶었지만, 시간 상의 이유로 미뤄왔는데 이번 주말에 Factorization Machine 논문을 읽어볼 생각이다. 정리까지 할 수 있을진 모르겠지만. ML Ops 공부 시작공모전이 끝나서 여유가 생기니까 전부터 하고 싶던 Ops를 시작하려 한다. 모두의 ML Ops(https://mlops-for-all.github.io)를 읽으면서 도커부터 설치했다. 도커와 쿠버네티스는 꼭 ops가 아니어도 쓸 줄 알아야 한다고 생각했는데 가볍게라도 익히고 가야겠다. 기술 블로그 맞나?한 주 동안 배운 걸 정리하고 싶어서 시작한 블로그였는데, 강의를 소화하는 것만으로도 시간이 부족해서 정리를 할 수가 없다. 결국 회고록만 적고 있는데 그래도 이렇게 정리해두는 게 의미있다고 생각한다. 적으면서 주간 학습 정리 게시판이 있던게 생각나서 한번 들어가봤는데, 다른 사람들도 간단하게 정리만 하는 수준으로 하고 있었다. 확실히 남들에게 어떻게 보일지 신경쓰면서 정리하긴 다들 어려운 듯 하다. 키워드 torch.mm / torch.matmul / torch.mul 차이 모두의 ML Ops (https://mlops-for-all.github.io)","link":"/2022/10/23/5%EC%A3%BC%EC%B0%A8%20%ED%9A%8C%EA%B3%A0%EB%A1%9D(%EA%B5%AC%ED%8C%80)/"},{"title":"6주차 회고록(기초 대회, VSC, 가우스랩)","text":"기초 대회 시작 이번 주부터 각 도메인 별 기초 대회를 시작한다. 개인 별로 v100 서버 하나씩 할당 받아 그 안에서 자유롭게 코딩을 할 수 있다. 서버 환경에서 코딩하는게 처음인데 세팅이 잘 되있어 그런지 연결 자체는 쉬웠다. 좋은 gpu가 주어졌을 때 다양한 모델과 방법론을 테스트 해봐야 할 것 같다. 근데 그걸 잘 할 수 있을지는..ㅎㅎ pycharm말고 vsc 요약 빠르고 가볍다 서버 연결 시 파일 시스템에 직접 접근해서 코딩할 수 있다. 파이참을 코딩 처음 시작할 때부터 써왔다. 파이참 말고 다른 에디터는 써보지도 않았고 vsc가 빠르고 가볍다는 말을 들었을 때도 별로 혹하진 않았다. 파이참이 무겁긴 해도 IDE와 에디터의 차이가 있을 거라고 생각했다. 물론 파이썬으로 개발을 하는게 아니라서 IDE로서의 장점도 사실 잘 못 느꼈다.. 지금 생각해보면 그냥 새로운 걸로 적응하기 귀찮아서 그랬던 것 같다. 이번에 파이참으로 서버환경에서 코딩하려는데, 내가 예상한 것과 다르게 됐다. 코랩에 연결했을 때는 그냥 인터프리터만 땡겨오는 거니까.. 라고 생각했는데, 이번 서버 환경에서도 코랩처럼 환경이 설정됐다. 난 에디터에서 연결하면 파일 시스템에도 접근할 수 있는 모습을 원했는데 로컬 파일 시스템으로만 접근이 됐다. 터미널도 접속이 안됐던 것 같은데 이건 잘 기억이 안난다. jetbrain client를 이용하면 내가 원하는 모습으로 서버 파일 시스템에 직접 접근해서 코딩하는 환경이 나오긴 했는데, 좀 뭔가 이상했다. vm 형태로 작동해서 메모리 제한도 걸려있고 여러모로 맘에 안들었다. (생각해보니 파이참도 vm형태로 작동해서 메모리 제한이 걸려있다.) vsc는 ssh로 연결하면 에디터에서 서버 파일 시스템에 접근할 수 있었다. 그리고 심지어 엄청 가벼워서 익스텐션을 웬만큼 추가해도 느려지지 않았다. 왜 나는 여태 파이참을 쓰고 있었을까.. 가우스랩 가우스랩에서 ML Ops 분야로 신입 채용을 진행했다. ML Ops로 준비된 포폴은 없었지만, 일단 넣었다. 주말에 진행되는 코테를 봤는데.. 한 문제도 못 풀었다. 알고리즘 공부를 좀 더 빡세게 할 필요성을 느꼈다. 양치기 + 이코테 같은 책들 보면서 문제 풀이 능력 좀 길러야 할 것 같다. users.csv의 location 값 채움 wandb -&gt; xgboost 모델은 pytorch와 방법이 다르다 https://docs.wandb.ai/guides/integrations/xgboost","link":"/2022/10/30/6%EC%A3%BC%EC%B0%A8%20%ED%9A%8C%EA%B3%A0%EB%A1%9D(%EA%B8%B0%EC%B4%88%20%EB%8C%80%ED%9A%8C,%20VSC)/"},{"title":"torch.mm&#x2F;torch.matmul&#x2F;torch.mul 비교","text":"다양한 torch의 행렬곱 메소드PyTorch에서는 행렬곱에 대한 메소드가 여러가지 있다. torch.mm, torch.matmul, torch.mul 각각 어떤 차이점이 있는지 알아보자 torch.mm torch.mm(input, mat2, *, out=None) → Tensor torch.mm은 브로드캐스팅이 일어나지 않는 행렬 곱연산이다. 즉, 기본적으로 연산이 가능한 shape일 때 곱이 일어나고 가능하지 않은 형태일 땐 에러를 일으킨다.input이 $(n \\times m)$이고 mat2가 $(m \\times p)$일 때 결과는 $(n \\times p)$형태의 텐서가 출력된다. 브로드캐스팅이 예상하지 못한 곳에서 일어나면 어디서 문제가 일어났는지 파악하기 힘들어진다. 디버깅할 때 편하려면 미리 텐서를 squeeze나 view 등으로 형태를 맞춰주고 torch.mm을 이용하는게 속 편하다. 123456789101112131415&gt;&gt;&gt; mat1 = torch.randn(2, 3)&gt;&gt;&gt; mat1tensor([[ 1.5311e+00, -1.2978e-03, -1.3174e-01], [ 3.7436e-01, 1.7078e-01, -1.4868e+00]])&gt;&gt;&gt; mat2 = torch.randn(3, 3)&gt;&gt;&gt; mat2tensor([[ 1.5622, -1.6235, -1.5933], [ 0.5857, -0.6801, 0.9272], [ 0.0267, -0.1720, -2.5046]])&gt;&gt;&gt; torch.mm(mat1, mat2)tensor([[ 2.3875, -2.4621, -2.1107], [ 0.6451, -0.4682, 3.2857]]) torch.matmul torch.matmul(input, other, *, out=None) → Tensor torch.matmul은 broadcasting이 일어나는 행렬 곱연산이다. 즉 형태가 맞지 않아도 곱연산이 진행된다. 123456789101112131415161718192021222324252627282930&gt;&gt;&gt; # vector x vector&gt;&gt;&gt; tensor1 = orch.randn(3)&gt;&gt;&gt; tensor2 = torch.randn(3)&gt;&gt;&gt; torch.matmul(tensor1, tensor2).size()torch.Size([])&gt;&gt;&gt; # matrix x vector&gt;&gt;&gt; tensor1 = torch.randn(3, 4)&gt;&gt;&gt; tensor2 = torch.randn(4)&gt;&gt;&gt; torch.matmul(tensor1, tensor2).size()torch.Size([3])&gt;&gt;&gt; # batched matrix x broadcasted vector&gt;&gt;&gt; tensor1 = torch.randn(10, 3, 4)&gt;&gt;&gt; tensor2 = torch.randn(4)&gt;&gt;&gt; torch.matmul(tensor1, tensor2).size()torch.Size([10, 3])&gt;&gt;&gt; # batched matrix x batched matrix&gt;&gt;&gt; tensor1 = torch.randn(10, 3, 4)&gt;&gt;&gt; tensor2 = torch.randn(10, 4, 5)&gt;&gt;&gt; torch.matmul(tensor1, tensor2).size()torch.Size([10, 3, 5])&gt;&gt;&gt; # batched matrix x broadcasted matrix&gt;&gt;&gt; tensor1 = torch.randn(10, 3, 4)&gt;&gt;&gt; tensor2 = torch.randn(4, 5)&gt;&gt;&gt; torch.matmul(tensor1, tensor2).size()torch.Size([10, 3, 5]) torch.mul torch.mul(input, other, *, out=None) → Tensor torch.mul은 element-wise($\\odot$) 등의 연산을 할 때 사용한다. 그래서 위 두 연산과 달리 other 파라미터에 tensor가 아닌 다른 자료형을 사용할 수 있다. 1234567891011121314151617181920&gt;&gt;&gt; a = torch.randn(3)&gt;&gt;&gt; atensor([ 0.2015, -0.4255, 2.6087])&gt;&gt;&gt; torch.mul(a, 100)tensor([ 20.1494, -42.5491, 260.8663])&gt;&gt;&gt; b = torch.randn(4, 1)&gt;&gt;&gt; btensor([[ 1.1207], [-0.3137], [ 0.0700], [ 0.8378]])&gt;&gt;&gt; c = torch.randn(1, 4)&gt;&gt;&gt; ctensor([[ 0.5146, 0.1216, -0.5244, 2.2382]])&gt;&gt;&gt; torch.mul(b, c)tensor([[ 0.5767, 0.1363, -0.5877, 2.5083], [-0.1614, -0.0382, 0.1645, -0.7021], [ 0.0360, 0.0085, -0.0367, 0.1567], [ 0.4312, 0.1019, -0.4394, 1.8753]]) Reference:https://pytorch.org/docs/stable/generated/torch.mm.htmlhttps://pytorch.org/docs/stable/generated/torch.matmul.html#torch.matmulhttps://pytorch.org/docs/stable/generated/torch.mul.html?highlight=torch%20mul#torch.mul","link":"/2022/10/23/torch%20%ED%96%89%EB%A0%AC%20%EA%B3%B1%20%EB%A9%94%EC%86%8C%EB%93%9C%20%EB%B9%84%EA%B5%90/"},{"title":"부스트코스 1주차 회고","text":"부스트코스를 진행한지 벌써 1주가 지났다. 프리코스에서 미리 공개됐던 강의들을 그대로 듣는 주차였기 때문에 부스트코스 자체만으로는 촉박하지 않았다. 다만 진행하던 파이토치 스터디도 있었고 내가 약하다고 생각한 AI Math 부분의 강좌는 다시 한번 더 들었기 때문에 여유롭지 않은 한 주였다. 게다가 심화과제는 생각한 것 보다 훨씬 어려웠다. 손도 못댄 문제들이 많았는데, 라이브러리를 모르거나 수식에 겁먹어서 필요 이상으로 쫄았던 부분도 있었다. 문제는 정말 문제 자체를 이해하지 못해서 풀지 못한 부분도 있었다는 점이다. 팀원들과도 이야기 했을 때 나만 그렇게 느낀 건 아니었다. 다행히 금요일에 오피스 아워를 통해 조교분들의 해설을 들을 수 있었다. 부스트코스를 한 주 동안 진행하면서 신청하길 잘했다고 생각이 든 부분이 많았다. 정말 질 좋은 강의와 과제, 운영진들의 케어, 심화과제에 대한 깔끔한 해설까지. 한달에 백단위씩 내고 다녔던 재수학원이 생각나던 한 주였다. 강의와 과제AI Math는 필수적으로 알아야할 키워드와 각 개념이 어떻게 AI에 쓰이는지 깔끔하게 정리해준다. 필요성과 깊이가지 챙겨갈 수 있는 좋은 강의였다. 난이도도 일부러 굳이 낮추지 않은 느낌이었는데 그 점이 오히려 좋았다. (물론 거의 이해 못한 채로 마무리하긴 했다.) 과제 역시 대학에서도 평 좋은 교수님의 과제를 보는 듯 했다. 그저 강의를 보기만 한게 아니라, 제대로 이해했는지 확인해볼 수 있는 내용이었다. 운영진의 케어부스트코스를 신청했을 때의 내 마음가짐은 어땠는지 잊지 않고 싶다. 잘한 것, 좋았던 것, 계속할 것잘못했던 것, 아쉬운 것, 부족한 것도전할 것, 시도할 것키워드 캐글 노트북 코랩보다 안정성이나 런타임 측면에서 더 좋다고 한다. 또 데이터를 업로드하고 다운로드하는 시간이 굉장히 빠르다. 캐글 컴피티션 code 카테고리 캐글 컴피티션 code 탭에서 baseline을 검색하면, 많은 사람들이 올려놓은 기본 코드라인을 볼 수 있다. scratch baseline 실제로 사용하는 모델들은 어떤 식으로 구현됐는지 알 수 있다.","link":"/2022/09/24/%EB%B6%80%EC%8A%A4%ED%8A%B8%EC%BD%94%EC%8A%A4-1%EC%A3%BC%EC%B0%A8-%ED%9A%8C%EA%B3%A0/"},{"title":"지원 배경 및 후기","text":"지원 배경 2022 전기 대학원에 떨어지고 개인적으로도 정말 힘든 일이 많았다. 처음 대학원이 떨어졌을 땐 포트폴리오를 제대로 만들고 부족한 부분도 공부하고 다시 지원하려 했다. 하지만 정신차리고 다시 마음을 다잡았을 때는 8월 말이었다. 공부를 하긴 했지만 그걸 블로그 등에 남긴 것도 아니었고 프로젝트 경험도 전혀 늘은 게 없었다. 컨택을 하기 위해 준비했던 건데 돌아보니 달라진게 없는 기분이었다. 이쯤 되자 정말 내가 대학원에 가고 싶은지, 데이터 관련 분야에서 일하고 싶은지 돌아보게 되었다. 결국 확신을 갖고 싶어 아무 부트캠프라도 들어가 프로젝트와 공부를 하고 싶었다. 사실 그전에는 부트캠프에 대해 부정적인 인식이 강했는데, 비전공자들이나 듣는 과정이라고 생각했기 때문이다. 하지만 냉정하게 내 자신을 평가했을 때 비전공자와 다를 바 없다는 생각이 들었고 부트캠프에 대해 알아보게 되었다. 고려사항 AI 트랙으로 부트캠프를 하는 곳은 많지 않았다. 네이버, 프로그래머스, 패스트캠퍼스, 엘리스코딩 등이 있었다. 다양한 후기를 찾아보고나서 내가 고려한 부분은 다음과 같았다. 코딩 테스트를 보는가 테스트를 준비하고 합격하는 사람들이 곧 그만큼 노력하고 열정이 있는 사람들일거라고 생각했다. 또, 팀 단위 과정이기 때문에 어느정도 수준이 있는 사람들과 같이 하고 싶었다. 대학원 다 떨어진 마당에 이걸 바라는게 웃기긴 하지만. AI를 서비스화하는 단계를 얼마나 다루는가 ML Ops 과정에 대해 배워보고 싶었다. 어떤 분야인지 궁금했다. 백엔드에 대한 부분을 얼마나 다루는가 ML을 서비스 하는 부분은 백엔드 지식이 필수다. 하지만 AI 트랙이기 때문에 이 부분이 주객전도가 일어나면 안된다고 생각했다. 백엔드만 주구장창 배운다는 느낌이 드는 곳은 피하고 싶었다. 공부를 하고 싶은 분위기를 만들어주는가 가장 중요하게 생각한 부분이다. 당연히 알아서 열심히 해야하지만, 그 환경을 잘 만들어주는 건 또 다른 이야기다. 가고 싶었던 곳 다양한 소개글, 영상, 후기를 봤을 때 가장 붙고 싶었던 곳은 네이버에서 진행하는 Boostcoursse - AI Tech와 프로그래머스에서 진행하는 Dev course였다. 부스트코스는 특히 참가한 사람들의 학습 환경을 만들어주기 위해 노력하는 것 같았다. 온보딩 키트라던지, 다양한 커뮤니티 이벤트라던지.. 또한 신청을 받으면서 시험 대비용 프리코스(Pre-course)를 열어줬는데 이 강의 퀄리티가 정말 좋았다. 혼자서 공부하던 내용들이 쭉 정리가 되는 느낌이었다. 알아봤을 때는 부스트코스의 지원기간이 일주일 정도 남아있었다. 어떻게든 자기소개서를 작성하고 노션에 포트폴리오를 만들었다. 노션 포트폴리오 구글링을 하고 그 중에서 가장 맘에 드는 템플릿으로 작성했다. 사실 담을 내용이 없어서 만들지말까 고민했지만, 어떻게든 어필하고 싶었다. 텅텅빈 깃허브와 스터디를 진행하면서 요약했던 것들을 노션에 담아 올렸다. 1차그 후,1차 테스트 볼 때는 프리코스를 다 듣진 못한채로 응시했다. 그래도 최대한 내용을 공부하고 문제를 풀 수 있을 수준으로 들었다고 생각했다. 근데 시험 창에 접속하자마자 좆됐다는 생각이 들었다. 1차에도 코테가 있었던 것이다. ‘태어나서 코테 공부 해본적이 없는데 어떡하지’라는 생각과 ‘시발 진짜 난 병신인가’하는 생각을 하면서 응시했다. 다행히 1차에서 보는 코테는 구현 문제 위주였다. 학교에서 내준 과제 수준이거나 그것보다 쉬웠기 때문에 열심히 풀었다. 아마 5문제 중에 3.5솔 정도 했던 것 같다. 오히려 생각보다 이론 부분이 쉽지 않았다. 지금 봐도 다 맞추진 못할 것 같다. 어찌어찌 1차를 치루고 오픈톡방 반응을 봤을 때, 난 딱 커트라인 수준이었기 때문에 조졌다 싶었다. 그래도 붙었을 때를 대비해서 2차 코딩 테스트를 준비했다. ‘이것이 코딩 테스트다’ 책을 보면서 동시에 오픈톡방에서 코테 스터디를 구해서 같이 프로그래머스 문제를 풀었다. 지금 확인해보니 lv.1은 39문제, lv.2는 12문제를 풀었다. 이걸 다 맞춘 건 아니고 lv.2 는 6문제 정도밖에 못 맞췄다.이코테 책은 끝까지 볼 필요가 없었고 볼 수도 없었다. 지금 다시 생각해보면 어떻게 붙었지? 싶다. 어쨌든 열심히 준비하는 와중에 1차 합격 메일을 받았고 힘을 내서 2차를 준비했다. 2차2차 시험을 보기 전날까지도 BFS/DFS는 풀지 못했고 DP는 한 두개 겨우 푸는 수준이었다. 긴장한 채로 응시했는데 내가 수준이 낮아서 그런지 대부분 구현 문제로 보였다. 마지막 문제정도가 DP였던 것 같다. DP정도 제외하면 조건도 널널했기 때문에 빡구현으로 해결할 수 있었다. 그럼 난 몇솔을 했을까? 7문제 중에 4.5솔을 했다. 다른 합격 후기글을 보면 5개는 풀어야 안정권이라는데 4.5솔을 했다. 시험보고 오픈톡방 반응도 비슷했다. 7솔한 사람도 많았고 대부분이 5솔은 했다. 조졌다고 생각하고 마음을 접고 프로그래머스 데브코스를 준비했다. 합격데브코스는 자기소개서도 빡세고 문제도 어렵다고 들어서 솔직히 준비할 때부터 쥰내 하기 싫었다. 부스트코스 때 열심히 했는데 떨어진 것도 영향이 있었고. 그냥 어떻게든 되겠지 하는 마음으로 침착맨이나 봤다. 근데 데브코스 코테 전날에 부스트코스 합격 메일이 왔다. 다행이다 싶었다 진짜. 이제 불태우는 일만 남았다고 생각하고 파이토치 스터디도 구했다. 코스가 시작되기 전까지 파이토치 스터디를 빡세게 진행하고 마침내 코스를 듣게 됐다.","link":"/2022/10/01/%EC%A7%80%EC%9B%90%ED%95%98%EA%B2%8C-%EB%90%9C-%EA%B3%84%EA%B8%B0/"},{"title":"13주차 회고록(번아웃, DKT 마무리, 기업연계 프로젝트, Multi-VAE)","text":"번아웃 거의 두달 동안 회고록을 쓰지 않았다. 7주차에 첫 번째 대회가 끝났는데 당시 번아웃이 좀 심하게 왔다. 대회가 진행되는 동안 내가 뭘 해야 할지 잘 모르겠다는 생각이 계속 들었다. 당연히 성취도 없는 기분이고 이는 번아웃을 더 가속화했다. 당시 팀원들이 소통과 공유가 잘 되는 분위기는 아니었는데, 다들 비슷하게 느꼈을 것 같다는 생각도 지금은 든다.이유는 모르겠지만, 프로젝트 경험이 처음은 아닌데 유달리 멘붕이 왔다. 나중에는 내가 AI 분야에 정말 적성이 맞을까 하는 생각만 들었다. 진지하게 ‘진로를 AI로 잡는걸 고민해봐야 하나’ 하는 생각도 들었지만, 내가 여유롭게 생각하고 있을 나이도 아니라는 걸 상기했다. 죽이되든 밥이되든 취업을 하고 회사생활을 해봐야 판단할 수 있지 않을까 하는 생각에 도달했을 때, 그리고 새로운 팀원들과 첫 오프라인 만남을 가졌을 때 번아웃을 극복할 수 있었다.번아웃을 극복하는 방법은 가지각색이겠지만, 난 모든 정서적인 문제는 사람들로 푸는 것 같다. 옛날에는 혼자서 앓다가 시간이 지나면 극복했다고 믿었는데 나이를 먹을수록 사람들을 만나는게 나에게 제일 잘 맞는 방법임을 깨닫게 된다. 새로운 사람들을 만나거나, 친한 친구들을 만나거나 어떻게 해서든 사람들을 만나려고 한다. 아이유가 우울할 때 그 기분에 속지 않도록 몸을 움직이라고 한 적이 있는데 역시 한국 최고의 아티스트. DKTDKT 대회가 끝났다. 이번에도 도중에 좀 현타가 왔었는데, 내가 뭘 해야 할지 잘 모르겠다고 느낀 점에서 비롯했다. 처음 대회를 시작할 때 개인 학습 목표를, 내가 도전해본 적 없는 PyTorch를 이용한 모델링에 초점을 맞췄는데 대회 내내 이를 지키지 못했다. 그냥 눈앞에 내가 할 수 있을 것만 같은 문제에만 매달리니 스트레스만 쌓였던 것 같다.팀원들 눈에도 내가 스트레스 받는 게 실시간으로 보였는지 동료 피드백에 위 내용이 적혀 있었다. 허허.. 땡큐 앤 고멘. 팀 프로젝트이고 인클래스 컴피티션이라고 해도 등수가 보이니 내가 잘할 수 있는 부분을 포기하기 쉽지 않았다. 근데 문제는 그래도 성과가 별로 없었다는 거였고.. 아무튼 이번 대회가 끝나고 팀원들끼리 회고할 때, 다음 대회 때는 정말로 리더보드 신경쓰지 말자는 의견이 나왔다. 적극 찬성했다.이번 대회에서 가장 기억에 남는건 git을 통한 협업과 시퀀셜 모델이었다. 먼저 git을 통한 협업은 내가 처음으로 해본 경험이었다. 모델 종류별로 브랜치를 나누고 그 위에서 각자 작업을 하다가 푸쉬할만한 코드 변경이 있다면, 푸쉬 후 이를 공유했다. 또, 2-3일에 한번씩 main 브랜치에 PR을 진행하는 경험도 기억에 남는다.다음으로 시퀀셜 모델은 항상 어렵게 느껴 피하다가 이번 대회에서 피할 수 없어 맞이했다. 성훈이형의 미친 캐리로 다양한 시퀀셜 모델로 대회를 진행할 수 있었고, 대회가 끝나고 Transformer를 다같이 구현하는 시간도 가질 수 있었다.DKT 대회 깃허브: https://github.com/boostcampaitech4lv23recsys2/level2_dkt_recsys-level2-recsys-11DKT 대회 Wrap-up Report: https://bit.ly/3j7fJiZ 기업연계 프로젝트(Upstage) 부스트캠프에서 진행하는 기업연계 프로젝트에 신청했고 합격했다. 사실 신청서 작성할 때 대회가 끝난 직후였기 때문에, 너무 할 일이 많았다. Wrap-up report 작성도 죽겠는데 신청서도 작성하려니 할일이 한두가지가 아니었다. 결국 대회가 끝난 목요일이후로 금요일부터 일요일까지 매일 오프라인 모임을 통해 어떻게든 마무리 지었다.이력서 쓴다는 생각으로 신청서를 작성하려고 노력했다. 우리의 어떤 점이 이 프로젝트와 fit할지 어필하고, 우리는 이 프로젝트를 어떻게 정의하고 분석했는지, 어떤 점을 제안할 수 있는지 중점적으로 작성했다. 또, 신청 직전에 받은 멘토님 피드백도 굉장히 큰 도움이 됐다. 대화를 나누며 받은 게 아니라 모든 부분을 반영할 수는 없었지만 그럼에도 내용이 상당히 풍부해졌다. 감사합니다 박정호 멘토님.신청서: https://bit.ly/3PEzI52 Multi-VAE(Multi-Variational Auto Encoder) 이번 Movie Recommendation의 스페셜 미션으로 Multi-VAE를 구현했다. 사실 기존 AutoEncoder도 잘 모르는데 강의를 통해 Multi-VAE 개요를 파악하고 그 후 논문 리뷰나 유튜브 영상 등을 통해 공부했다. 코드의 DAE 구현 부분을 참고하며 작성하니 3-4시간만에 구현을 할 수 있었다. 다만 코드로 구현하는 건 할만한데 수식을 완전히 이해하진 못하겠다. MLE에서 출발하는데 MLE가 그림으로는 이해가 되지만 수식으로 나오면 항상 개념이 헷갈린다. 이 주의 노래","link":"/2022/12/19/post/"}],"tags":[{"name":"부스트코스, boostcourse","slug":"부스트코스-boostcourse","link":"/tags/%EB%B6%80%EC%8A%A4%ED%8A%B8%EC%BD%94%EC%8A%A4-boostcourse/"},{"name":"PyTorch","slug":"PyTorch","link":"/tags/PyTorch/"}],"categories":[{"name":"Boostcourse AI Tech 4기","slug":"Boostcourse-AI-Tech-4기","link":"/categories/Boostcourse-AI-Tech-4%EA%B8%B0/"},{"name":"PyTorch","slug":"PyTorch","link":"/categories/PyTorch/"}],"pages":[{"title":"about","text":"","link":"/about/index.html"}]}